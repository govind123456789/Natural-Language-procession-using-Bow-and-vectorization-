{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/company-stock-and-investment/Company Stock and Investment.csv',index_col=['Date'], parse_dates=['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings                                  # `do not disturbe` mode\nwarnings.filterwarnings('ignore')\n\nimport numpy as np                               # vectors and matrices\nimport pandas as pd                              # tables and data manipulations\nimport matplotlib.pyplot as plt                  # plots\nimport seaborn as sns                            # more plots\n\nfrom dateutil.relativedelta import relativedelta # working with dates with style\nfrom scipy.optimize import minimize              # for function minimization\n\nimport statsmodels.formula.api as smf            # statistics and econometrics\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs\n\nfrom itertools import product                    # some useful functions\nfrom tqdm import tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/company-stock-and-investment/Company Stock and Investment.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date']=pd.to_datetime(df['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.sort_values(by='Date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df.tail(200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df1.set_index(df1['Date']).drop('Date', 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['Other sharesInvestments'].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,7))\nplt.plot(df1['Other sharesInvestments'])\nplt.title('Other sharesInvestments')\nplt.grid(True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df1.drop(['Oil Investments','Gold Investments','Comp Stock'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Min:\",df1.index.min())\nprint(\"Max:\",df1.index.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,5))\ndf1['Other sharesInvestments'].plot()\nplt.title(\"Other sharesInvestments\",fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings                                  # `do not disturbe` mode\nwarnings.filterwarnings('ignore')\n\nimport numpy as np                               # vectors and matrices\nimport pandas as pd                              # tables and data manipulations\nimport matplotlib.pyplot as plt                  # plots\nimport seaborn as sns                            # more plots\n\nfrom dateutil.relativedelta import relativedelta # working with dates with style\nfrom scipy.optimize import minimize              # for function minimization\n\nimport statsmodels.formula.api as smf            # statistics and econometrics\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs\n\nfrom itertools import product                    # some useful functions\nfrom tqdm import tqdm_notebook\n\n\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\nfrom sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n\ndef mean_absolute_percentage_error(y_true, y_pred): \n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def moving_average(series, n):\n    \"\"\"\n        Calculate average of last n observations\n    \"\"\"\n    return np.average(series[-n:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotMovingAverage(series, window, plot_intervals=False, scale=1.96, plot_anomalies=False):\n\n    \"\"\"\n        series - dataframe with timeseries\n        window - rolling window size \n        plot_intervals - show confidence intervals\n        plot_anomalies - show anomalies \n\n    \"\"\"\n    rolling_mean = series.rolling(window=window).mean()\n\n    plt.figure(figsize=(15,5))\n    plt.title(\"Moving average\\n window size = {}\".format(window))\n    plt.plot(rolling_mean, \"g\", label=\"Rolling mean trend\")\n\n    # Plot confidence intervals for smoothed values\n    if plot_intervals:\n        mae = mean_absolute_error(series[window:], rolling_mean[window:])\n        deviation = np.std(series[window:] - rolling_mean[window:])\n        lower_bond = rolling_mean - (mae + scale * deviation)\n        upper_bond = rolling_mean + (mae + scale * deviation)\n        plt.plot(upper_bond, \"r--\", label=\"Upper Bond / Lower Bond\")\n        plt.plot(lower_bond, \"r--\")\n        \n        # Having the intervals, find abnormal values\n        if plot_anomalies:\n            anomalies = pd.DataFrame(index=series.index, columns=series.columns)\n            anomalies[series<lower_bond] = series[series<lower_bond]\n            anomalies[series>upper_bond] = series[series>upper_bond]\n            plt.plot(anomalies, \"ro\", markersize=10)\n        \n    plt.plot(series[window:], label=\"Actual values\")\n    plt.legend(loc=\"upper left\")\n    plt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotMovingAverage(df1, 12) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotMovingAverage(df1, 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotMovingAverage(df1, 24) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotMovingAverage(df['Other sharesInvestments'], 4, plot_intervals=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weighted_average(series, weights):\n    \"\"\"\n        Calculate weighter average on series\n    \"\"\"\n    result = 0.0\n    weights.reverse()\n    for n in range(len(weights)):\n        result += series.iloc[-n-1] * weights[n]\n    return float(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weighted_average(df1, [0.6, 0.3, 0.1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def exponential_smoothing(series, alpha):\n    \"\"\"\n        series - dataset with timestamps\n        alpha - float [0.0, 1.0], smoothing parameter\n    \"\"\"\n    result = [series[0]] # first value is same as series\n    for n in range(1, len(series)):\n        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotExponentialSmoothing(series, alphas):\n    \"\"\"\n        Plots exponential smoothing with different alphas\n        \n        series - dataset with timestamps\n        alphas - list of floats, smoothing parameters\n        \n    \"\"\"\n    with plt.style.context('seaborn-white'):    \n        plt.figure(figsize=(15, 7))\n        for alpha in alphas:\n            plt.plot(exponential_smoothing(series, alpha), label=\"Alpha {}\".format(alpha))\n        plt.plot(series.values, \"c\", label = \"Actual\")\n        plt.legend(loc=\"best\")\n        plt.axis('tight')\n        plt.title(\"Exponential Smoothing\")\n        plt.grid(True);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotExponentialSmoothing(df1['Other sharesInvestments'], [0.3, 0.05])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def double_exponential_smoothing(series, alpha, beta):\n    \"\"\"\n        series - dataset with timeseries\n        alpha - float [0.0, 1.0], smoothing parameter for level\n        beta - float [0.0, 1.0], smoothing parameter for trend\n    \"\"\"\n    # first value is same as series\n    result = [series[0]]\n    for n in range(1, len(series)+1):\n        if n == 1:\n            level, trend = series[0], series[1] - series[0]\n        if n >= len(series): # forecasting\n            value = result[-1]\n        else:\n            value = series[n]\n        last_level, level = level, alpha*value + (1-alpha)*(level+trend)\n        trend = beta*(level-last_level) + (1-beta)*trend\n        result.append(level+trend)\n    return result\n\ndef plotDoubleExponentialSmoothing(series, alphas, betas):\n    \"\"\"\n        Plots double exponential smoothing with different alphas and betas\n        \n        series - dataset with timestamps\n        alphas - list of floats, smoothing parameters for level\n        betas - list of floats, smoothing parameters for trend\n    \"\"\"\n    \n    with plt.style.context('seaborn-white'):    \n        plt.figure(figsize=(20, 8))\n        for alpha in alphas:\n            for beta in betas:\n                plt.plot(double_exponential_smoothing(series, alpha, beta), label=\"Alpha {}, beta {}\".format(alpha, beta))\n        plt.plot(series.values, label = \"Actual\")\n        plt.legend(loc=\"best\")\n        plt.axis('tight')\n        plt.title(\"Double Exponential Smoothing\")\n        plt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotDoubleExponentialSmoothing(df['Other sharesInvestments'], alphas=[0.9, 0.02], betas=[0.9, 0.02])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotDoubleExponentialSmoothing(df1['Other sharesInvestments'], alphas=[0.9, 0.02], betas=[0.9, 0.02])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Ho: It is non stationary\n#H1: It is stationary\n\ndef adfuller_test(sales):\n    result=adfuller(sales) # same as above ,variable name changed\n    labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n    for value,label in zip(result,labels):\n        print(label+' : '+str(value) )\n    if result[1] <= 0.05:\n        print(\"strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data  is stationary\")\n    else:\n        print(\"weak evidence against null hypothesis, time series is non-stationary \")\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adfuller_test(df['Other sharesInvestments'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom subprocess import check_output\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nfrom pandas.plotting import lag_plot\nfrom pandas import datetime\nfrom statsmodels.tsa.arima_model import ARIMA\nwarnings.filterwarnings('ignore')\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/company-stock-and-investment/Company Stock and Investment.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['Other sharesInvestments']].plot()\nplt.title(\"company\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dr = df.cumsum()\ndr.plot()\nplt.title('Cumulative Returns')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,10))\nlag_plot(df['Other sharesInvestments'], lag=1)\nplt.title('Autocorrelation plot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=df.drop(['Oil Investments', 'Gold Investments',\n       'Comp Stock'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, test_data = df1[0:int(len(df1)*0.8)], df1[int(len(df1)*0.8):]\nplt.figure(figsize=(12,7))\nplt.title('Prices')\nplt.xlabel('Dates')\nplt.ylabel('Prices')\nplt.plot(df1['Other sharesInvestments'], 'blue', label='Training Data')\nplt.plot(test_data['Other sharesInvestments'], 'green', label='Testing Data')\nplt.xticks(np.arange(0,1983, 300), df['Date'][0:1983:300])\nplt.legend()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def smape_kun(y_true, y_pred):\n    return np.mean((np.abs(y_pred - y_true) * 200/ (np.abs(y_pred) + np.abs(y_true))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ar = train_data['Other sharesInvestments'].values\ntest_ar = test_data['Other sharesInvestments'].values\n\n\nhistory = [x for x in train_ar]\nprint(type(history))\npredictions = list()\nfor t in range(len(test_ar)):\n    model = ARIMA(history, order=(5,1,0))\n    model_fit = model.fit(disp=0)\n    output = model_fit.forecast()\n    yhat = output[0]\n    predictions.append(yhat)\n    obs = test_ar[t]\n    history.append(obs)\n    #print('predicted=%f, expected=%f' % (yhat, obs))\nerror = mean_squared_error(test_ar, predictions)\nprint('Testing Mean Squared Error: %.3f' % error)\nerror2 = smape_kun(test_ar, predictions)\nprint('Symmetric mean absolute percentage error: %.3f' % error2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\nplt.plot(df1['Other sharesInvestments'], 'green', color='blue', label='Training Data')\nplt.plot(test_data.index, predictions, color='green', marker='o', linestyle='dashed', \n         label='Predicted Price')\nplt.plot(test_data.index, test_data['Other sharesInvestments'], color='red', label='Actual Price')\nplt.title('Prices Prediction')\nplt.xlabel('Dates')\nplt.ylabel('Prices')\nplt.xticks(np.arange(0,1983, 300), df['Date'][0:1983:300])\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getWeights(d,lags):\n    # return the weights from the series expansion of the differencing operator\n    # for real orders d and up to lags coefficients\n    w=[1]\n    for k in range(1,lags):\n        w.append(-w[-1]*((d-k+1))/k)\n    w=np.array(w).reshape(-1,1) \n    return w\ndef plotWeights(dRange, lags, numberPlots):\n    weights=pd.DataFrame(np.zeros((lags, numberPlots)))\n    interval=np.linspace(dRange[0],dRange[1],numberPlots)\n    for i, diff_order in enumerate(interval):\n        weights[i]=getWeights(diff_order,lags)\n    weights.columns = [round(x,2) for x in interval]\n    fig=weights.plot(figsize=(15,6))\n    plt.legend(title='Order of differencing')\n    plt.title('Lag coefficients for various orders of differencing')\n    plt.xlabel('lag coefficients')\n    #plt.grid(False)\n    plt.show()\ndef ts_differencing(series, order, lag_cutoff):\n    # return the time series resulting from (fractional) differencing\n    # for real orders order up to lag_cutoff coefficients\n    \n    weights=getWeights(order, lag_cutoff)\n    res=0\n    for k in range(lag_cutoff):\n        res += weights[k]*series.shift(k).fillna(0)\n    return res[lag_cutoff:] \nplotWeights([0.1,0.9],20,5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,7))\nplt.plot(test_data.index, predictions, color='black', marker='o', linestyle='dashed', \n         label='Predicted Price')\nplt.plot(test_data.index, test_data['Other sharesInvestments'], color='red', label='Actual Price')\nplt.xticks(np.arange(1486,1983, 60), df['Date'][1486:1983:60])\nplt.title('  Prediction')\nplt.xlabel('Dates')\nplt.ylabel('Prices')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = df1\nplt.figure(figsize=(12,7))\nplt.title('Prices')\nplt.xlabel('Dates')\nplt.ylabel('Prices')\nplt.plot(df1['Other sharesInvestments'], 'blue', label='Training Data')\nplt.xticks(np.arange(0,1983, 300), df['Date'][0:1983:300])\nplt.legend()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_model=pd.Series(model_fit.fittedvalues, copy=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fit.plot_predict(1,2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(pred_model.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_model_cumsum =pred_model.cumsum()\nprint(pred_model_cumsum)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_model_log =pd.Series(df1['Other sharesInvestments'],index=df.index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_model_log =pred_model_log.add(pred_model_cumsum,fill_value=0)\npred_model_log.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred =np.exp(pred_model_log)\nplt.plot(df1['Other sharesInvestments'])\nplt.plot(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=model_fit.forecast(steps=36)\nprint(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}