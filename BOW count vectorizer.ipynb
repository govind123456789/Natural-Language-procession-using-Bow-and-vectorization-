{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=['#pmo']\n",
    "for i in x:\n",
    "    def tweets():\n",
    "        import GetOldTweets3 as got\n",
    "        tweetCriteria =got.manager.TweetCriteria().setQuerySearch(i) \\\n",
    "            .setSince(\"2020-07-30\") \\\n",
    "            .setUntil(\"2020-07-31\") \\\n",
    "            .setMaxTweets(1)\n",
    "        # Creation of list that contains all tweets\n",
    "        tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "        # Creating list of chosen tweet data\n",
    "        text_tweets = [[tweet.text] for tweet in tweets]\n",
    "        return text_tweets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(text_tweets, countvect):\n",
    "    terms_doc = countvect.fit_transform(text_tweets)\n",
    "    return pd.DataFrame(terms_doc.toarray(),columns=countvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading text file\n",
    "text = \"\"\n",
    "text_tweets = tweets()\n",
    "\n",
    "length = len(text_tweets)\n",
    "\n",
    "for i in range(0, length):\n",
    "    text = text_tweets[i][0] + \" \" + text\n",
    "\n",
    "# converting to lowercase\n",
    "lower_case = text.lower()\n",
    "\n",
    "# Removing punctuations\n",
    "cleaned_text = lower_case.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# splitting text into words\n",
    "tokenized_words = cleaned_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Close personal relationship between #Trudeau, the Prime Minister of Canada and a shady charitable organization to which he started giving $1bil of taxpayers money brought out a lot of questions out for #PMO &amp; #Liberals even now supporting #trudeau. #WEscam'],\n",
       " ['प्रधानमंत्री फसल बीमा योजना किसानों को आपदा से हुए नुकसान से राहत दिलाने वाली योजना है। इसके अंतर्गत न्यूनतम प्रीमियम देकर, किसान बुआई से कटाई तक प्राकृतिक आपदाओं से हुए नुकसान का उचित भुगतान पा सकता है। और जानिए: http://www.pmfby.gov.in #PMKisan #AatmaNirbharKrishi'],\n",
       " ['Si tienes proyectos que NO son exitosos, tus clientes no se encuentra Satisfechos o si requieres crear cultura de proyectos en tu empresa, crear una Oficina de Proyectos #PMO visita http://www.blogelvisdom.com.ve/ #Lima #PMP'],\n",
       " ['SCHOOL SPORTS PHYSICALS: School is right around the corner and that means so is Fall Sports. At Physical Medicine of Oklahoma we are offering school sports physicals for $20. Call (405) 726-2727 to book your appointment. #PMO #FullyIntegratedMultiSpecialtyClinic']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tweets=\"\"\"[['MoU between India & Zimbabwe on traditional medicine, homeopathy #Homeopathy #India&amp;ampZimbabwe #MoU #Traditionalmedicine']]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n",
    "              \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\",\n",
    "              \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\",\n",
    "              \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n",
    "              \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\",\n",
    "              \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n",
    "              \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n",
    "              \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
    "              \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "# Removing stop words from the tokenized words list\n",
    "final_words = [word for word in tokenized_words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words : ['amp', 'ampzimbabwe', 'between', 'homeopathy', 'india', 'medicine', 'mou', 'on', 'traditional', 'traditionalmedicine', 'zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "# Example of single document\n",
    "# Without stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "text_tweets=[text_tweets]\n",
    "\n",
    "# This step will convert text into tokens \n",
    "vect1 = CountVectorizer()\n",
    "\n",
    "vect1.fit_transform(text_tweets)\n",
    "print(\"bag of words :\",vect1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mou': 6,\n",
       " 'between': 2,\n",
       " 'india': 4,\n",
       " 'zimbabwe': 10,\n",
       " 'on': 7,\n",
       " 'traditional': 8,\n",
       " 'medicine': 5,\n",
       " 'homeopathy': 3,\n",
       " 'amp': 0,\n",
       " 'ampzimbabwe': 1,\n",
       " 'traditionalmedicine': 9}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect1.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "c_vect = CountVectorizer()\n",
    "\n",
    "c_vect.fit(text_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Present at  [[1 0 1 0 0 0 0 0 0 0 0]]\n",
      "original indexes ['amp', 'ampzimbabwe', 'between', 'homeopathy', 'india', 'medicine', 'mou', 'on', 'traditional', 'traditionalmedicine', 'zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "string2 = ['Close personal relationship between #Trudeau, the Prime Minister of Canada and a shady charitable organization to which he started giving $1bil of taxpayers money brought out a lot of questions out for #PMO &amp; #Liberals even now supporting #trudeau. #WEscam']\n",
    "\n",
    "c_new_vect = c_vect.transform(string2)\n",
    "\n",
    "print (\"Text Present at \",c_new_vect.toarray())\n",
    "\n",
    "\n",
    "print (\"original indexes\", vect1.get_feature_names() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words : ['amp', 'ampzimbabwe', 'between', 'homeopathy', 'india', 'medicine', 'mou', 'on', 'traditional', 'traditionalmedicine', 'zimbabwe']\n",
      "vocab        : {'mou': 6, 'between': 2, 'india': 4, 'zimbabwe': 10, 'on': 7, 'traditional': 8, 'medicine': 5, 'homeopathy': 3, 'amp': 0, 'ampzimbabwe': 1, 'traditionalmedicine': 9}\n"
     ]
    }
   ],
   "source": [
    "vect1.fit_transform(text_tweets)\n",
    "print(\"bag of words :\",vect1.get_feature_names())\n",
    "print(\"vocab        :\",vect1.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below metrix is the Bag of Words approach\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1bil</th>\n",
       "      <th>20</th>\n",
       "      <th>2727</th>\n",
       "      <th>405</th>\n",
       "      <th>726</th>\n",
       "      <th>amp</th>\n",
       "      <th>and</th>\n",
       "      <th>apple</th>\n",
       "      <th>appointment</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>una</th>\n",
       "      <th>ve</th>\n",
       "      <th>visita</th>\n",
       "      <th>we</th>\n",
       "      <th>wescam</th>\n",
       "      <th>which</th>\n",
       "      <th>will</th>\n",
       "      <th>words</th>\n",
       "      <th>www</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1bil  20  2727  405  726  amp  and  apple  appointment  are  ...  una  ve  \\\n",
       "0     1   0     0    0    0    1    1      0            0    0  ...    0   0   \n",
       "1     0   0     0    0    0    0    0      0            0    0  ...    1   1   \n",
       "2     0   1     1    1    1    0    1      0            1    1  ...    0   0   \n",
       "3     0   0     0    0    0    0    1      1            0    0  ...    0   0   \n",
       "\n",
       "   visita  we  wescam  which  will  words  www  your  \n",
       "0       0   0       1      1     0      0    0     0  \n",
       "1       1   0       0      0     0      0    1     0  \n",
       "2       0   1       0      0     0      0    0     1  \n",
       "3       0   0       0      0     1      1    0     0  \n",
       "\n",
       "[4 rows x 102 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tweets = ['Close personal relationship between #Trudeau, the Prime Minister of Canada and a shady charitable organization to which he started giving $1bil of taxpayers money brought out a lot of questions out for #PMO &amp; #Liberals even now supporting #trudeau. #WEscam','Si tienes proyectos que NO son exitosos, tus clientes no se encuentra Satisfechos o si requieres crear cultura de proyectos en tu empresa, crear una Oficina de Proyectos #PMO visita http://www.blogelvisdom.com.ve/ #Lima #PMP','SCHOOL SPORTS PHYSICALS: School is right around the corner and that means so is Fall Sports. At Physical Medicine of Oklahoma we are offering school sports physicals for $20. Call (405) 726-2727 to book your appointment. #PMO #FullyIntegratedMultiSpecialtyClinic','Similar words tend to occur together and will have similar context for example – Apple is a fruit. Mango is a fruit' ]\n",
    "\n",
    "c_vect = CountVectorizer()\n",
    "print (\"Below metrix is the Bag of Words approach\")\n",
    "bow(text_tweets, c_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram  : ['an', 'example', 'gram', 'is', 'of', 'this']\n",
      "2-gram  : ['an example', 'example of', 'is an', 'of gram', 'this is']\n",
      "3-gram  : ['an example of', 'example of gram', 'is an example', 'this is an']\n",
      "4-gram  : ['an example of gram', 'is an example of', 'this is an example']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer ,TfidfVectorizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "string = [\"This is an example of n-gram!\"]\n",
    "\n",
    "vect1 = CountVectorizer(ngram_range=(1,1))\n",
    "\n",
    "vect1.fit_transform(string)\n",
    "\n",
    "vect2 = CountVectorizer(ngram_range=(2,2))\n",
    "vect2.fit_transform(string)\n",
    "\n",
    "vect3 = CountVectorizer(ngram_range=(3,3))\n",
    "vect3.fit_transform(string)\n",
    "\n",
    "vect4 = CountVectorizer(ngram_range=(4,4))\n",
    "vect4.fit_transform(string)\n",
    "\n",
    "print(\"1-gram  :\",vect1.get_feature_names())\n",
    "\n",
    "print(\"2-gram  :\",vect2.get_feature_names())\n",
    "print(\"3-gram  :\",vect3.get_feature_names())\n",
    "print(\"4-gram  :\",vect4.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tweets = [' #PMO #FullyIntegratedMultiSpecialtyClinic','Similar words tend to occur together and will have similar context for example – Apple is a fruit. Mango is a fruit' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>apple</th>\n",
       "      <th>context</th>\n",
       "      <th>example</th>\n",
       "      <th>for</th>\n",
       "      <th>fruit</th>\n",
       "      <th>fullyintegratedmultispecialtyclinic</th>\n",
       "      <th>have</th>\n",
       "      <th>is</th>\n",
       "      <th>mango</th>\n",
       "      <th>occur</th>\n",
       "      <th>pmo</th>\n",
       "      <th>similar</th>\n",
       "      <th>tend</th>\n",
       "      <th>to</th>\n",
       "      <th>together</th>\n",
       "      <th>will</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  apple  context  example  for  fruit  \\\n",
       "0  0.0    0.0      0.0      0.0  0.0    0.0   \n",
       "1  0.2    0.2      0.2      0.2  0.2    0.4   \n",
       "\n",
       "   fullyintegratedmultispecialtyclinic  have   is  mango  occur       pmo  \\\n",
       "0                             0.707107   0.0  0.0    0.0    0.0  0.707107   \n",
       "1                             0.000000   0.2  0.4    0.2    0.2  0.000000   \n",
       "\n",
       "   similar  tend   to  together  will  words  \n",
       "0      0.0   0.0  0.0       0.0   0.0    0.0  \n",
       "1      0.4   0.2  0.2       0.2   0.2    0.2  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer()\n",
    "bow(text_tweets,tf)\n",
    "bow(text_tweets,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "Tfvectorizer = TfidfVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "X = vectorizer.fit_transform(text_tweets)\n",
    "Y = Tfvectorizer.fit_transform(text_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names \n",
      " ['and will', 'apple is', 'context for', 'example apple', 'for example', 'fruit mango', 'have similar', 'is fruit', 'mango is', 'occur together', 'pmo fullyintegratedmultispecialtyclinic', 'similar context', 'similar words', 'tend to', 'to occur', 'together and', 'will have', 'words tend']\n",
      "Array \n",
      " [[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 2 1 1 0 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Names \\n\",vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "print('Array \\n',X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names \n",
      " ['and will', 'apple is', 'context for', 'example apple', 'for example', 'fruit mango', 'have similar', 'is fruit', 'mango is', 'occur together', 'pmo fullyintegratedmultispecialtyclinic', 'similar context', 'similar words', 'tend to', 'to occur', 'together and', 'will have', 'words tend']\n",
      "Array \n",
      " [[0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.        1.        0.        0.        0.\n",
      "  0.        0.        0.        0.       ]\n",
      " [0.2236068 0.2236068 0.2236068 0.2236068 0.2236068 0.2236068 0.2236068\n",
      "  0.4472136 0.2236068 0.2236068 0.        0.2236068 0.2236068 0.2236068\n",
      "  0.2236068 0.2236068 0.2236068 0.2236068]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Names \\n\",vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "print('Array \\n',Y.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
